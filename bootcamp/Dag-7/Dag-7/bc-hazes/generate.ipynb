{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, GRU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from random import randint\n",
    "from keras.models import model_from_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a corpus of 41701 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"hazes.txt\") as corpus_file:\n",
    "    corpus = corpus_file.read()\n",
    "    corpus = corpus.lower()\n",
    "print(\"Loaded a corpus of {0} characters\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               86016     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 39)                5031      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 39)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 91,047\n",
      "Trainable params: 91,047\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Build our network from loaded architecture and weights\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "with open('model.json', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "model = model_from_json(data)\n",
    "\n",
    "\n",
    "model.load_weights('weights-20.hdf5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a unique identifier for each char in the corpus, then make some dicts to ease encoding and decoding\n",
    "\n",
    "# Get the unique characters in the corpus\n",
    "# sort them in alphabetical order\n",
    "chars = sorted(list(set(corpus)))\n",
    "\n",
    "# Set the length of the input sentence\n",
    "sentence_length = 20\n",
    "\n",
    "# Get the total number of unique characters\n",
    "num_chars = len(chars)\n",
    "\n",
    "# Create a dictionary that maps each character to a numerical value\n",
    "encoding = {c: i for i, c in enumerate(chars)}\n",
    "\n",
    "# Create a dictionary that maps each numerical value back to its corresponding character\n",
    "decoding = {i: c for i, c in enumerate(chars)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "  if temperature <= 0:\n",
    "    return np.argmax(preds)\n",
    "  preds = np.asarray(preds).astype('float64')\n",
    "  preds = np.log(preds) / temperature\n",
    "  exp_preds = np.exp(preds)\n",
    "  preds = exp_preds / np.sum(exp_preds)\n",
    "  probas = np.random.multinomial(1, preds, 1)\n",
    "  return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seed_pattern):\n",
    "        X = np.zeros((1, sentence_length, num_chars), dtype=bool)\n",
    "        #print(X.shape)\n",
    "        for i, character in enumerate(seed_pattern):\n",
    "            X[0, i, encoding[character]] = 1\n",
    "        \n",
    "        generated_text = \"\"\n",
    "        for i in range(500):\n",
    "            # even de temperatuur toevoegen.\n",
    "            prediction = sample(model.predict(X, verbose=0)[0],0.5)\n",
    "            generated_text += decoding[prediction]\n",
    "\n",
    "            activations = np.zeros((1, 1, num_chars), dtype=bool)\n",
    "            activations[0, 0, prediction] = 1\n",
    "            X = np.concatenate((X[:, 1:, :], activations), axis=1)\n",
    "\n",
    "        return generated_text\n",
    "\n",
    "def make_seed(seed_phrase=\"\"):\n",
    "        if seed_phrase:\n",
    "            phrase_length = len(seed_phrase)\n",
    "            pattern = \"\"\n",
    "            for i in range (0, sentence_length):\n",
    "                pattern += seed_phrase[i % phrase_length]\n",
    "        else:\n",
    "            seed = randint(0, corpus_length - sentence_length)\n",
    "            pattern = abba_corpus[seed:seed + sentence_length]\n",
    "\n",
    "        return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ik geloof in mezelf \n",
      "oh jij alls al geweld\n",
      "\n",
      "je heb je zijn deer staan\n",
      "in deroof jij naar dij welder\n",
      "dat ik echt niet meer\n",
      "je haar techund gaan\n",
      "wat ik jou niet kijkt bedomen\n",
      "en wiet ik mij zo verden\n",
      "ik hou van jou, maar ik heb het zenden\n",
      "maar ja ik zo dan had\n",
      "met is je nooit maar ik weer een stouwen gedacht\n",
      "als je diekelen\n",
      "want vengen lieg, ook is het voorbij,\n",
      "\n",
      "joh, ja aat je vrienden anner\n",
      "als zij ik mijn hielper te van messt er kurste hag\n",
      "je blijft toel verdeel veeg ouwer jou gezelt\n",
      "ik wil je niet meer dat vergelez\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 20\n",
    "seed = make_seed('ik geloof in mezelf ')\n",
    "print(seed)\n",
    "txt =  generate(seed)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample song\n",
    "In the bard and show you on your lovelight and i can't get the mowner i'm a marion an and every mind, there's a boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
