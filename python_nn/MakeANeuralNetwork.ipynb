{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.93276101],\n       [0.89508859],\n       [0.8909408 ]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "def check(x):\n",
    "    return (x>0) * x\n",
    "\n",
    "def make_weights(nr_neurons, inputs):\n",
    "    return np.random.rand(nr_neurons, inputs) - 0.5\n",
    "    \n",
    "def make_biases(nr_neurons):\n",
    "    return np.random.rand(nr_neurons, 1)\n",
    "\n",
    "def feed_forward(layer, input_data):\n",
    "   result = layer['weights'] @ input_data + layer['biases']\n",
    "   result = layer['actief'](result)\n",
    "   return  result\n",
    "\n",
    "def Dense(nr_neurons, inputs, actif):\n",
    "    W = check(make_weights(nr_neurons,inputs))\n",
    "    B = check(make_biases(nr_neurons))\n",
    "    return {\"weights\": W, \"biases\": B, \"actief\": actif}\n",
    "\n",
    "W = check(make_weights(3,2))\n",
    "B = check(make_biases(2))\n",
    "Layer = Dense(3,2,check)\n",
    "\n",
    "feed_forward(Layer, B)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een @ is ee nmatrix vermeningvuldiging"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## __init__(self, inputnodes, hiddennodes, outputnodes, learningrate)\n",
    "This method is the constructor of the neuralNetwork class, which is called when you create a new instance of the class. It takes four arguments:\n",
    "\n",
    "- inputnodes: The number of nodes in the input layer of the neural network.\n",
    "- hiddennodes: The number of nodes in the hidden layer of the neural network.\n",
    "- outputnodes: The number of nodes in the output layer of the neural network.\n",
    "- learningrate: The learning rate of the neural network, which controls how quickly the network adapts to new data.\n",
    "\n",
    "## train(self, inputs_list, targets_list)\n",
    "This method is used to train the neural network on a given set of inputs and targets. It takes two arguments:\n",
    "\n",
    "- inputs_list: A list of input values.\n",
    "- targets_list: A list of target values.\n",
    "\n",
    "## query(self, inputs_list)\n",
    "This method is used to get the output of the neural network for a given set of inputs. It takes one argument:\n",
    "\n",
    "- inputs_list: A list of input values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "import numpy as np\n",
    "\n",
    "class neuralNetwork:\n",
    "    \"\"\"\n",
    "    The __init__ method initializes the neural network by setting the number of nodes in each layer, generating random weights for the connections between the input and hidden layers (wih) and the hidden and output layers (who), and setting the activation function to the sigmoid function.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.inodes = input_nodes\n",
    "        self.hnodes = hidden_nodes\n",
    "        self.onodes = output_nodes\n",
    "        self.wih = np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "        self.lr = learning_rate\n",
    "        self.activation_function = expit\n",
    "\n",
    "    \"\"\"\n",
    "    The train method first converts the input and target lists to 2D numpy arrays and transposes them. It then calculates the output of the neural network for the given inputs, calculates the error between the output and the targets, and backpropagates the error through the network to update the weights.\n",
    "    \"\"\"\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        hidden_inputs = self.wih.dot(inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = self.who.dot(hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = self.who.T.dot(output_errors)\n",
    "        self.who += self.lr * (output_errors * final_outputs * (1.0 - final_outputs)) @ hidden_outputs.T\n",
    "        self.wih += self.lr * (hidden_errors * hidden_outputs * (1.0 - hidden_outputs)) @ inputs.T\n",
    "\n",
    "    \"\"\"\n",
    "    The method first converts the input list to a 2D numpy array and transposes it. It then calculates the output of the neural network for the given inputs and returns it.\n",
    "    \"\"\"\n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        hidden_inputs = self.wih.dot(inputs)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        final_inputs = self.who.dot(hidden_outputs)\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 3\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes, learning_rate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.54440149],\n       [0.6428091 ],\n       [0.28394414]])"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query (doesn't mean anything useful yet)\n",
    "n.query([1.0, 0.5, -1.5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Initialize weights\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        m = X.shape[0]  # number of samples\n",
    "\n",
    "        # Backward propagation\n",
    "        self.dz2 = self.a2 - y\n",
    "        self.dW2 = (1 / m) * np.dot(self.a1.T, self.dz2)\n",
    "        self.db2 = (1 / m) * np.sum(self.dz2, axis=0, keepdims=True)\n",
    "        self.dz1 = np.dot(self.dz2, self.W2.T) * self.a1 * (1 - self.a1)\n",
    "        self.dW1 = (1 / m) * np.dot(X.T, self.dz1)\n",
    "        self.db1 = (1 / m) * np.sum(self.dz1, axis=0, keepdims=True)\n",
    "\n",
    "        # Gradient descent parameter update\n",
    "        self.W2 -= learning_rate * self.dW2\n",
    "        self.b2 -= learning_rate * self.db2\n",
    "        self.W1 -= learning_rate * self.dW1\n",
    "        self.b1 -= learning_rate * self.db1\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward and backward pass\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "            # Print loss every 100 epochs\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                loss = np.mean(np.square(output - y))\n",
    "                print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.2504\n",
      "Epoch 200/1000, Loss: 0.2499\n",
      "Epoch 300/1000, Loss: 0.2495\n",
      "Epoch 400/1000, Loss: 0.2491\n",
      "Epoch 500/1000, Loss: 0.2485\n",
      "Epoch 600/1000, Loss: 0.2479\n",
      "Epoch 700/1000, Loss: 0.2470\n",
      "Epoch 800/1000, Loss: 0.2459\n",
      "Epoch 900/1000, Loss: 0.2445\n",
      "Epoch 1000/1000, Loss: 0.2426\n",
      "Predictions:\n",
      "[[0.51632765]\n",
      " [0.48755879]\n",
      " [0.52068837]\n",
      " [0.45971085]]\n"
     ]
    }
   ],
   "source": [
    "# Create a neural network with 2 input units, 3 hidden units, and 1 output unit\n",
    "nn = NeuralNetwork(2, 3, 1)\n",
    "\n",
    "# Generate some random training data\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Train the neural network\n",
    "nn.train(X, y, epochs=1000, learning_rate=0.1)\n",
    "\n",
    "# Make predictions on new data\n",
    "new_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "predictions = nn.predict(new_data)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
