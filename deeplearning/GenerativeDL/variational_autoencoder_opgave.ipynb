{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "    \n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (28, 28, 1)\n",
    "z_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(input_dim, name = 'encoder_input')\n",
    "\n",
    "x = Conv2D(filters = 32,\n",
    "           kernel_size = 3,\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_1')(encoder_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = 3,\n",
    "           strides = (2,2),\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_2')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = 3,\n",
    "           strides = (2,2),\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_3')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 32,\n",
    "           kernel_size = 3,\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_4')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "x = Flatten()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De encoder komt overeen met de `encoder` van de autoencoder. Het verschil zit in de volgende stap, waarin twee parallele Dense lagen het gemiddelde en de log van de variantie teruggeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = Dense(z_dim, name = 'mu')(x)\n",
    "log_var = Dense(z_dim, name = 'log_var')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    mu, log_var = args\n",
    "    epsilon = K.random_normal(shape = K.shape(mu), mean = 0, stddev =  1.)\n",
    "    return mu + K.exp(log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een `Lambda` laag is een manier om een willekeurige bewerking in een Keras laag uit te voeren.\n",
    "Onderstaande laag kiest een willekeurig getal volgens de verdeling bepaald door `mu` en `log_var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output = Lambda(sampling, name = 'encoder_output')([mu, log_var])\n",
    "\n",
    "encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bekijk de `summary` van de encoder. Komt deze overeen met je verwachtingen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "De `decoder` komt overeen met de `decoder` van de Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input((z_dim,), name = 'decoder_input')\n",
    "\n",
    "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = Reshape(shape_before_flattening)(x) # van een dense vector naar de vorm van een afbeelding\n",
    "\n",
    "x = Conv2DTranspose(filters = 64,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_1')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 64,\n",
    "                kernel_size = 3,\n",
    "                strides = (2,2),\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_2')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 32,\n",
    "                kernel_size = 3,\n",
    "                strides = (2,2),\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_3')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 1,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_4')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "decoder_output = Activation('sigmoid')(x)\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De volledige variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = Model(encoder_input, decoder(encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_loss_factor = 1500\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return r_loss_factor * K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "def vae_kl_loss(y_true, y_pred):\n",
    "    return -0.5 * K.sum(1 + log_var - K.square(mu) - K.exp(log_var), axis = 1)\n",
    "\n",
    "def vae_loss(y_true, y_pred):\n",
    "    return r_loss(y_true, y_pred) + vae_kl_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compileer en train de variational autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "vae.compile(optimizer = optimizer, loss = vae_loss,  metrics = [r_loss, vae_kl_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 20000\n",
    "\n",
    "vae.fit(x = x_train[:subset], y = x_train[:subset], batch_size = 32, epochs = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructie van originele afbeeldingen\n",
    "\n",
    "We selecteren willekeurige afbeeldingen, coderen deze met de `encoder` en decoderen deze met de `decoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "\n",
    "# selecteer willekeurige afbeeldingen uit x_test\n",
    "idx = np.random.choice(range(len(x_test)), n)\n",
    "test_images = x_test[idx]\n",
    "\n",
    "# vertaal met de encoder naar getallen\n",
    "z_points = encoder.predict(test_images)\n",
    "\n",
    "# vertaal de getallen met de decoder terug naar afbeeldingen\n",
    "reconstr_images = decoder.predict(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n):\n",
    "    img = test_images[i].reshape((28,28))\n",
    "    ax = fig.add_subplot(2, n, i + 1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)   \n",
    "    ax.imshow(img, cmap='gray_r')\n",
    "    \n",
    "for i in range(n):\n",
    "    img = reconstr_images[i].reshape((28,28))\n",
    "    ax = fig.add_subplot(2, n, i + n + 1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat valt je op aan de reconstructies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om een beter beeld te krijgen van het gedrag van de autoencoder, plotten we de outputs van de encoder (de 'z-waarden') voor een deel van de testset. De kleur van een punt geeft het correcte label weer.\n",
    "\n",
    "Daarnaast selecteren we alvast een aantal willekeurige punten (dus een combinatie van twee willekeurige getallen) die we dadelijk gaan gebruiken om volledig nieuwe afbeeldingen te genereren. Deze punten worden in het rood weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "grid_size = 10\n",
    "grid_depth = 3\n",
    "figsize = 12\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n)\n",
    "test_images = x_test[example_idx]\n",
    "test_labels = y_test[example_idx]\n",
    "\n",
    "z_points = encoder.predict(test_images)\n",
    "\n",
    "min_x = min(z_points[:, 0])\n",
    "max_x = max(z_points[:, 0])\n",
    "min_y = min(z_points[:, 1])\n",
    "max_y = max(z_points[:, 1])\n",
    "\n",
    "plt.figure(figsize=(figsize, figsize))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap = 'rainbow' , c = test_labels\n",
    "            , alpha=0.5, s=2)\n",
    "plt.colorbar()\n",
    "\n",
    "x = np.random.normal(size = grid_size * grid_depth)\n",
    "y = np.random.normal(size = grid_size * grid_depth)\n",
    "z_grid = np.array(list(zip(x, y)))\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'red', alpha=1, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat valt je op aan deze plot, vergeleken met dezelfde plot bij de Autoencoder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken nu de decoder om op basis van de willekeurig gegenereerde punten volledig nieuwe afbeeldingen te genereren en plotten deze afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst = decoder.predict(z_grid)\n",
    "\n",
    "figsize = 15\n",
    "fig = plt.figure(figsize=(figsize, grid_depth))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_size*grid_depth):\n",
    "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    \n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Varieer nu eens met het aantal lagen en filters in de encoder en decoder of met `z_dim` het aantal waarden in de vector `z`. Kun je de decoder een volledig andere vorm geven dan de encoder? Hoe beïnvloedt dit het resultaat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
