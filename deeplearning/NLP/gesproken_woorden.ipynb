{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './tensorflow-speech-recognition-challenge/'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train/audio')\n",
    "test_dir = os.path.join(data_dir, 'test/audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualiseer de data\n",
    "\n",
    "Laten we eerst eens naar een enkel bestand kijken waarin het woord 'cat' wordt uitgesproken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_filename = os.path.join(train_dir, 'cat/00b01445_nohash_0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\senne\\AppData\\Local\\Temp\\ipykernel_22220\\689624781.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  samples_cat, sample_rate = librosa.load(example_filename)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './tensorflow-speech-recognition-challenge/train/audio\\\\cat/00b01445_nohash_0.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLibsndfileError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:176\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[0m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 176\u001B[0m     y, sr_native \u001B[38;5;241m=\u001B[39m \u001B[43m__soundfile_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m sf\u001B[38;5;241m.\u001B[39mSoundFileRuntimeError \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m    179\u001B[0m     \u001B[38;5;66;03m# If soundfile failed, try audioread instead\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:209\u001B[0m, in \u001B[0;36m__soundfile_load\u001B[1;34m(path, offset, duration, dtype)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;66;03m# Otherwise, create the soundfile object\u001B[39;00m\n\u001B[1;32m--> 209\u001B[0m     context \u001B[38;5;241m=\u001B[39m \u001B[43msf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSoundFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m context \u001B[38;5;28;01mas\u001B[39;00m sf_desc:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\soundfile.py:658\u001B[0m, in \u001B[0;36mSoundFile.__init__\u001B[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001B[0m\n\u001B[0;32m    656\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info \u001B[38;5;241m=\u001B[39m _create_info_struct(file, mode, samplerate, channels,\n\u001B[0;32m    657\u001B[0m                                  \u001B[38;5;28mformat\u001B[39m, subtype, endian)\n\u001B[1;32m--> 658\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode_int\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosefd\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    659\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mset\u001B[39m(mode)\u001B[38;5;241m.\u001B[39missuperset(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mseekable():\n\u001B[0;32m    660\u001B[0m     \u001B[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\soundfile.py:1216\u001B[0m, in \u001B[0;36mSoundFile._open\u001B[1;34m(self, file, mode_int, closefd)\u001B[0m\n\u001B[0;32m   1215\u001B[0m     err \u001B[38;5;241m=\u001B[39m _snd\u001B[38;5;241m.\u001B[39msf_error(file_ptr)\n\u001B[1;32m-> 1216\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LibsndfileError(err, prefix\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError opening \u001B[39m\u001B[38;5;132;01m{0!r}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname))\n\u001B[0;32m   1217\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode_int \u001B[38;5;241m==\u001B[39m _snd\u001B[38;5;241m.\u001B[39mSFM_WRITE:\n\u001B[0;32m   1218\u001B[0m     \u001B[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001B[39;00m\n\u001B[0;32m   1219\u001B[0m     \u001B[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001B[39;00m\n\u001B[0;32m   1220\u001B[0m     \u001B[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001B[39;00m\n",
      "\u001B[1;31mLibsndfileError\u001B[0m: Error opening './tensorflow-speech-recognition-challenge/train/audio\\\\cat/00b01445_nohash_0.wav': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m samples_cat, sample_rate \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample_filename\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m librosa\u001B[38;5;241m.\u001B[39mdisplay\u001B[38;5;241m.\u001B[39mwaveshow(samples_cat, sr \u001B[38;5;241m=\u001B[39m sample_rate)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:184\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path, (\u001B[38;5;28mstr\u001B[39m, pathlib\u001B[38;5;241m.\u001B[39mPurePath)):\n\u001B[0;32m    181\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    182\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPySoundFile failed. Trying audioread instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    183\u001B[0m     )\n\u001B[1;32m--> 184\u001B[0m     y, sr_native \u001B[38;5;241m=\u001B[39m \u001B[43m__audioread_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    186\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\decorator.py:232\u001B[0m, in \u001B[0;36mdecorate.<locals>.fun\u001B[1;34m(*args, **kw)\u001B[0m\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwsyntax:\n\u001B[0;32m    231\u001B[0m     args, kw \u001B[38;5;241m=\u001B[39m fix(args, kw, sig)\n\u001B[1;32m--> 232\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m caller(func, \u001B[38;5;241m*\u001B[39m(extras \u001B[38;5;241m+\u001B[39m args), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\util\\decorators.py:60\u001B[0m, in \u001B[0;36mdeprecated.<locals>.__wrapper\u001B[1;34m(func, *args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001B[39;00m\n\u001B[0;32m     52\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mDeprecated as of librosa version \u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mIt will be removed in librosa version \u001B[39m\u001B[38;5;132;01m{:s}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     58\u001B[0m     stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,  \u001B[38;5;66;03m# Would be 2, but the decorator adds a level\u001B[39;00m\n\u001B[0;32m     59\u001B[0m )\n\u001B[1;32m---> 60\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\librosa\\core\\audio.py:241\u001B[0m, in \u001B[0;36m__audioread_load\u001B[1;34m(path, offset, duration, dtype)\u001B[0m\n\u001B[0;32m    238\u001B[0m     reader \u001B[38;5;241m=\u001B[39m path\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m# If the input was not an audioread object, try to open it\u001B[39;00m\n\u001B[1;32m--> 241\u001B[0m     reader \u001B[38;5;241m=\u001B[39m \u001B[43maudioread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maudio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m reader \u001B[38;5;28;01mas\u001B[39;00m input_file:\n\u001B[0;32m    244\u001B[0m     sr_native \u001B[38;5;241m=\u001B[39m input_file\u001B[38;5;241m.\u001B[39msamplerate\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\audioread\\__init__.py:127\u001B[0m, in \u001B[0;36maudio_open\u001B[1;34m(path, backends)\u001B[0m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m BackendClass \u001B[38;5;129;01min\u001B[39;00m backends:\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 127\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mBackendClass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m DecodeError:\n\u001B[0;32m    129\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\audioread\\rawread.py:59\u001B[0m, in \u001B[0;36mRawAudioFile.__init__\u001B[1;34m(self, filename)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, filename):\n\u001B[1;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_file \u001B[38;5;241m=\u001B[39m aifc\u001B[38;5;241m.\u001B[39mopen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fh)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './tensorflow-speech-recognition-challenge/train/audio\\\\cat/00b01445_nohash_0.wav'"
     ]
    }
   ],
   "source": [
    "samples_cat, sample_rate = librosa.load(example_filename)\n",
    "\n",
    "librosa.display.waveshow(samples_cat, sr = sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(samples_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ter vergelijking bekijken we een opname van het woord 'dog'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example_filename = os.path.join(train_dir, 'dog/0a7c2a8d_nohash_0.wav')\n",
    "\n",
    "samples_dog, sample_rate = librosa.load(example_filename)\n",
    "\n",
    "librosa.display.waveshow(samples_dog, sr = sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotten de frequenties in een klein stuk van de opname van 'cat'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 2048\n",
    "plt.plot(np.abs(librosa.stft(samples_cat[:n_fft], n_fft=n_fft, hop_length = n_fft + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een spectogram laat de geluidsintensiteit op verschillende frequenties uitgezet in de tijd zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat\n",
    "\n",
    "hop_length = 512\n",
    "\n",
    "stft = np.abs(librosa.stft(samples_cat, n_fft = n_fft, hop_length = hop_length))\n",
    "DB = librosa.amplitude_to_db(stft, ref=np.max)\n",
    "\n",
    "librosa.display.specshow(DB, sr = sample_rate, x_axis = 'time', y_axis = 'log');\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dog\n",
    "\n",
    "stft = np.abs(librosa.stft(samples_dog, n_fft = n_fft, hop_length = hop_length))\n",
    "DB = librosa.amplitude_to_db(stft, ref=np.max)\n",
    "\n",
    "librosa.display.specshow(DB, sr = sample_rate, x_axis = 'time', y_axis = 'log');\n",
    "plt.colorbar(format='%+2.0f dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCC features proberen de belangrijkste informatie in een spraaksignaal te representeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(samples_cat, sr = sample_rate, n_mfcc = 13)\n",
    "librosa.display.specshow(mfccs, x_axis='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Herkennen van woorden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen de MFCC representatie gebruiken als input voor een deep learning model. We gaan proberen om een aantal verschillend woorden te herkennen met behulp van een LSTM. \n",
    "\n",
    "Je kunt eventueel meer labels toevoegen (namen van de mappen in de dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['cat', 'dog', 'yes', 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepareer de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zetten alle opnamen van de betreffende woorden om in MFCC features. We kiezen hier voor 13 MFCC features die we elke 10 ms berekenen voor een stukje van 25 ms van het spraaksignaal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "max_len = 80 # om ons model iets te vereenvoudingen gebruiken we een vaste lengte voor de inputs\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    wav_dir = os.path.join(train_dir, label)\n",
    "    waves = [f for f in os.listdir(wav_dir) if f.endswith('.wav')]\n",
    "    \n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(os.path.join(wav_dir, wav), sr = 16000)\n",
    "        mfccs = librosa.feature.mfcc(samples, sr = sample_rate, n_mfcc = 13, hop_length=int(sample_rate/100), n_fft=int(sample_rate/40))\n",
    "        \n",
    "        if (mfccs.shape[1] > max_len): # sla opnamen die te kort zijn over\n",
    "            mfccs = mfccs[:, :max_len]\n",
    "        \n",
    "            X_train.append(mfccs)\n",
    "            y_train.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We brengen X_train en y_train in de juiste vorm om gebruikt te worden door `keras` modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mX_train\u001B[49m)\n\u001B[0;32m      2\u001B[0m X_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mswapaxes(X_train, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      3\u001B[0m X_train\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = np.swapaxes(X_train, 1, 2)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(np.array(y_train))\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecteer een model, train, verbeter, evalueer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer met geschikte Deep Learning modellen. Welk model werkt het beste?\n",
    "\n",
    "Tip 1: de input heeft de vorm: `input_shape = (80, 13)`.\n",
    "\n",
    "Tip 2: Dropout kan helpen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zijn er woorden die de modellen vaak door elkaar halen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonusvraag: Hierboven hebben we plaatjes gemaakt van de data. We zouden deze afbeeldingen als input kunnen beschouwen. We zien iedere input dan dus als een twee-dimensionale afbeelding en kunnen deze classificeren met modellen voor beeldherkenning. Maak zo'n model.\n",
    "\n",
    "Het is dan wel nodig om de vorm van `X_train` en `X_val` zo aan te passen dat deze een 'kleuren kanaal' hebben. Je kunt dit op de MFCC features doen, maar ook op een spectogram. gebruik hiervoor `librosa.melspectogram`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
