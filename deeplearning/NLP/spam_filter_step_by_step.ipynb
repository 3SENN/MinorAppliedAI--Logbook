{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit notebook maken we een spamfilter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verover de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken gebruik van publieke data van Apache Spamassassin. Deze data gaan we downloaden van het internet. Zorg dat hieronder bij `SPAM_PATH` de naam van de map staat waar je het resultaat wilt opslaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
    "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
    "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
    "\n",
    "# verander onderstaande url in de map waarin je het resultaat wilt opslaan\n",
    "SPAM_PATH = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dafdaf\n"
     ]
    }
   ],
   "source": [
    "print(\"dafdaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken een pythonfunctie om de bestanden van internet te halen. Zoek uit wat deze functie doet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_spam_data(spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
    "    if not os.path.isdir(spam_path):# als de map nog niet bestaat...\n",
    "        os.makedirs(spam_path)\n",
    "    \n",
    "    for filename, url in ((\"ham.tar.bz2\", HAM_URL), (\"spam.tar.bz2\", SPAM_URL)):\n",
    "        path = os.path.join(spam_path, filename)\n",
    "        \n",
    "        if not os.path.isfile(path): # als het bestand nog niet bestaat...\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "        \n",
    "        tar_bz2_file = tarfile.open(path)\n",
    "        tar_bz2_file.extractall(path=SPAM_PATH)\n",
    "        tar_bz2_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het aanroepen van de functie moet er een map `easy_ham` en een map `spam` zijn toegevoegd binnen `SPAM_PATH`. Roep de functie aan en controleer dat dit het geval is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mfetch_spam_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 3\u001B[0m, in \u001B[0;36mfetch_spam_data\u001B[1;34m(spam_url, spam_path)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch_spam_data\u001B[39m(spam_url\u001B[38;5;241m=\u001B[39mSPAM_URL, spam_path\u001B[38;5;241m=\u001B[39mSPAM_PATH):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(spam_path):\u001B[38;5;66;03m# als de map nog niet bestaat...\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m         \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mspam_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filename, url \u001B[38;5;129;01min\u001B[39;00m ((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mham.tar.bz2\u001B[39m\u001B[38;5;124m\"\u001B[39m, HAM_URL), (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspam.tar.bz2\u001B[39m\u001B[38;5;124m\"\u001B[39m, SPAM_URL)):\n\u001B[0;32m      6\u001B[0m         path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(spam_path, filename)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[1;34m(name, mode, exist_ok)\u001B[0m\n\u001B[0;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: ''"
     ]
    }
   ],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om makkelijk bij de bestanden te kunnen, maken we voor beide categorieÃ«n een lijst met bestandsnamen.\n",
    "\n",
    "De methode `os.listdir()` geeft je een lijst van bestandsnamen in een map. Die kunnen we eventueel sorteren met `sorted()`. We gebruiken deze functies om zowel voor ham als voor spam een lijst te maken van alle bestandsnamen waarvan de lengte groter is dan 20 tekens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
    "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
    "\n",
    "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
    "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeveel bestanden met spam zijn er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoeveel bestanden zonder spam (met ham) zijn er?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we eens zo'n bestand bekijken, bijvoorbeeld het 4e bestand zonder spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SPAM_PATH, 'easy_ham', ham_filenames[3])) as myfile:\n",
    "    lines = myfile.readlines()\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierboven zie je de ruwe tekst van de e-mail. We kunnen dit iets leesbaarder maken door te zorgen dat elke nieuwe regel in het bestand ook op een eigen regel wordt afgedrukt. Bekijk vervolgens de tekst. Wat valt je op?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SPAM_PATH, 'easy_ham', ham_filenames[3])) as myfile:\n",
    "    for line in myfile.readlines():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat we zien, is een e-mail zoals een e-mailprogramma dit ontvangt. Een e-mail bestaat uit een header, waar aan we o.a. kunnen zien wie de afzender en ontvanger zijn en langs welke tussenstations de mail verstuurd is. Na de header volgt een lege regel en dan de inhoud van de e-mail.\n",
    "\n",
    "We kunnen de emails inlezen als tekstbestanden zoals we zojuist hebben gedaan, maar dan zal blijken dat sommig e-mails ander gecodeerd zijn en we niet alle bestanden kunnen openen. In plaats daarvan laten we Python het werk voor ons opknappen door de `email` library te gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
    "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
    "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken met behulp van de functie `load_email` nu een lijst met ham emails en een lijst met spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
    "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Druk ter controle een ham email en een spam email af. Gebruik hiervoor de methode 'as_string()' van het 'email' object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maak de data geschikt voor Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu hebben we onze data in de vorm van lijsten met e-mails. Om machine learning toe te kunnen passen hebben we echter getallen nodig. In de volgende stappen passen we de data zo aan dat deze bruikbaar wordt voor machine learning.\n",
    "\n",
    "We werken dit eerst uit op een enkel bestand om het daarna in een functie op alle emails toe te passen.\n",
    "\n",
    "We maken alleen gebruik van de tekst van de e-mails (hoewel er in de headers vast ook allerlei nuttige informatie staat om te bepalen of het om spam gaat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "body = spam_emails[13].get_content().strip()\n",
    "print(body[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sommige e-mails bevatten HTML code. Om deze te verwijderen maken we gebruik van een library met de naam `Beautiful Soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(body, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = soup.get_text()\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam bevat vaker html dan andere e-mails, dus we willen wel weten of een e-mail html bevat. We tellen we het aantal html-tags met behulp van `Beautiful Soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhtml = len(soup.find_all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om dezelfde reden zijn het aantal links naar websites ook interessant (een link heeft html code `a`). Tel ook deze met `Beautiful Soup` en sla het resultaat op in een variable `nlinks`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlinks = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voeg nu voor elke keer dat een htmltag voorkomt het woord `\" htmltag \"` aan de tekst van de e-mail toe en voeg voor elke keer dat een link voorkomt het woord `\" htmllink \"` toe. Op deze manier coderen we deze informatie in de tekst zelf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = body + nhtml*\" htmltag \" + nlinks*\" linktag \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zet nu alle tekst om naar kleine letters (lowercase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = body.lower()\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De tekst bevat nu nog onnodige lege regels. Deze kunnen we verwijderen met een zogenaamde reguliere expressie. Zoek uit wat de volgende code doet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "body = re.sub(r'(\\s*\\n)+', '\\n', body)\n",
    "\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maak nu zelf onderstaande regular expression af, zodat deze alle opeenvolgende spaties en tabs vervangt door een enkele spatie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = re.sub(r\" \", \" \", body)\n",
    "\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nummers en getallen in tekst zijn lastig omdat er heel veel verschillende van zijn. Het is maar de vraag of bijvoorbeeld een datum iets zegt over spam. We gaan daarom alle getallen vervangen door het woord `\" NUMMMER \"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = re.sub(r\"\\b[\\d.]+\\b\", \" NUMMER \", body)\n",
    "\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen met behulp van reguliere expressies ook leestekens verwijderen en e-mailadressen en namen van websites verwijderen. We voegen dit alles samen in een functie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_email(text):\n",
    "    #vervang urls door 'httpadr'\n",
    "    text = re.sub(r\"(http|https)://[^\\s]*\", 'httpaddr', text)\n",
    "    \n",
    "    #vervang emailadressen door 'emailadr'\n",
    "    text = re.sub(r\"\\b[^\\s]+@[^\\s]+[.][^\\s]+\\b\", 'emailadr', text)\n",
    "    \n",
    "    # verwijder alle leestekens\n",
    "    text = re.sub(r\"([^\\w\\s]+)|([_-]+)\", \" \", text)\n",
    "    \n",
    "    # vervang alle enters door ' newline '\n",
    "    text = re.sub(r\"\\n\", \" newline \", text)\n",
    "    \n",
    "    # vervang opeenvolgende spaties en tabs door een enkele spatie\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    #vervang getallen door 'NUMMER'\n",
    "    text = re.sub(r\"\\b[\\d.]+\\b\", \" NUMMER \", text)\n",
    "    \n",
    "    # verwijder onnodige spaties aan begin en eind\n",
    "    text = text.strip(\" \")\n",
    "    \n",
    "    return text\n",
    "\n",
    "body = clean_email(body)\n",
    "print (body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het resultaat van al onze inspanningen is een lijst met alleen maar woorden gescheiden door spaties.\n",
    "\n",
    "Maak nu een functie `email_to_text()` die als argument een email krijgt en als resultaat de lijst met woorden in de email teruggeeft.\n",
    "\n",
    "Deze functie combineert dus bovenstaande stappen: haal met `Beautiful Soup` de tekst uit de e-mail, tel het aantal html tags en links en voegt hier speciale woorden voor toe. Zet vervolgens alle tekst om naar kleine letter en verwijder getallen en leestekens met behulp van `clean_email()`.\n",
    "\n",
    "Zet deze stappen tussen `try:` en `except:`. Dit deel van de code is al gegeven en zorgt ervoor dat emails die fouten veroorzaken (omdat ze onleesbare tekens of bijvoorbeeld attachments bevatten) worden overgeslagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    try: \n",
    "        \n",
    "        # voeg hier de stappen toe om een lijst met woorden uit een e-mail te halen.\n",
    "        \n",
    "        return body\n",
    "    except: # handel onleesbare e-mails (i.v.m. attachment) af\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met behulp van deze functie kunnen we nu onze data in het juist formaat brengen om een classifier te trainen.\n",
    "Maak een vector X met alle emails en een target vector y met de bijbehorende labels. Kies bijvoorbeeld 0 als label voor ham en 1 voor spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ham_emails + spam_emails)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits de data in een training set en een test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We willen nu ieder email omzetten naar een vector met getallen. Deze vector bevat een getal voor elk woord dat voorkomt in de dataset. Voor elke email tellen we vervolgens hoe vaak ieder woord voorkomt in die e-mail, dit zijn de features van de e-mails. (Omdat lang niet ieder woord voorkomt in iedere e-mail, zullen heel veel van deze getallen 0 zijn).\n",
    "\n",
    "We hoeven dit gelukkig niet zelf te doen. sklearn geeft ons de `CountVectorizer` die precies dit doet. Zoek uit hoe deze werkt en pas deze toe op `X_train` om een dataset `X_vec_train` van feature vectoren te krijgen.\n",
    "\n",
    "`CountVectorizer` heeft als input een lijst met strings van woorden gescheiden door spaties nodig.\n",
    "Merk ook op dat `CountVectorizer` een optioneel argument preprocessor heeft, dat verwijst naar een functie die de ingevoerde data omzet naar zo'n string. Dit is precies de functie `email_to_text()` die wij zojuist gemaakt hebben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(preprocessor=email_to_text, min_df = 15)\n",
    "\n",
    "X_vec_train = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onze features bestaan nu dus uit getallen. `CountVectorizer` heeft een functie `get_feature_names()` die op volgorde de woorden teruggeeft die bij deze features horen. Gebruik deze functie om een Pandas `DataFrame` te maken waarmee we de dataset kunnen bekijken. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_vec_train.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zet nu ook de test data in `X_test` om naar features. Let op: hiervoor gebruik je de codering die de vectorizer op basis van `X_train` 'geleerd' heeft. Zoek, als je dat niet al gedaan hebt, in de documentatie het verschil tussen de functies `fit()`, `transform()` en `fit_transform()` op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train en test nu een classifier of deep learning model op basis van deze data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
